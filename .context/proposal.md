# 提案ドキュメント

## ゴール
- libcstを用いてPythonファイルからdocstringとコメントを抽出する
- オプションでprint文およびlogger呼び出しのメッセージ文字列も抽出できるようにする
- 抽出結果とメタ情報をJSONL形式で蓄積し、後続の翻訳処理（別途LLM）に渡す
- 処理件数や総テキスト量、処理時間などの最低限の観測指標を取得する

## アプローチ案
- ファイル探索から抽出、JSONL生成までを関数ベースのパイプラインで構成する
- 抽出器はlibcstのVisitorを利用してdocstringとコメント、任意のprint/logger呼び出しを検出する
- 並列化は`concurrent.futures`のThreadPoolExecutorを第一候補とし、ファイルI/O中心の負荷に対応する
- 処理対象は拡張子`.py`を前提とし、マッチ条件は設定ファイルもしくはCLI引数で切り替えできるようにする
- 翻訳処理はモック関数で置き、後続の統合時に差し替えやすい形にする

## データフォーマット検討
- JSONLはストリーミング処理しやすく、大容量でも追記で扱えるため現状の要件に適合
- 各行に`{"path": str, "kind": str, "text": str, "meta": {...}}`の形式で保存する案を推奨
- 代替案としてはParquet（高速読み書き＋型情報保持）やSQLite（更新や検索が柔軟）があるが、初期実装速度と取り回しを優先してJSONL継続を提案
- 翻訳後のデータも同じJSONLで保持し、before/afterを別フィールドに持たせると差分追跡が容易

## 観測性メモ
- ログは処理開始・終了、ファイル数、抽出件数、総文字数、経過時間を標準出力に記録
- 必要に応じて`logging`モジュールでINFOレベル出力をまとめ、GitHub Actions移行時も同じログを利用

## 今後の拡張余地
- 抽出対象の細分化（例えばdocstringの最初の1行のみなど）
- JSONL出力の分割（ファイルサイズ閾値でローテーション）
- Pathフィルタを設定ファイル（toml）に切り出し、GitHub Actionsからも流用
- 翻訳API連携と差し戻しロジックの実装
