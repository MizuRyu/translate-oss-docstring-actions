from __future__ import annotations

import argparse
import json
from pathlib import Path
import sys

ROOT = Path(__file__).resolve().parents[1]
SRC_DIR = ROOT / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from util import count_tokens


def parse_args() -> argparse.Namespace:
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æã™ã‚‹"""

    parser = argparse.ArgumentParser(
        description="JSONLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚µãƒãƒªã‚’è¨ˆç®—ã™ã‚‹ãƒ„ãƒ¼ãƒ«",
    )
    parser.add_argument("--input", required=True, help="å…¥åŠ› JSONL ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument(
        "--output",
        required=True,
        help="ã‚µãƒãƒªã‚’æ›¸ãå‡ºã™ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="ç¿»è¨³ä»¶æ•°ã®ä¸Šé™ï¼ˆtranslation_limitï¼‰",
    )
    return parser.parse_args()


def summarize_tokens(input_path: Path, limit: int | None = None) -> dict[str, float | int]:
    """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚µãƒãƒªã‚’è¨ˆç®—ã™ã‚‹"""

    items = 0
    tokens = 0
    chars = 0
    limited_tokens = 0
    limited_chars = 0
    max_tokens = 0
    min_tokens = float('inf')
    
    with input_path.open(encoding="utf-8") as handle:
        for line in handle:
            line = line.strip()
            if not line:
                continue
            record = json.loads(line)
            text = record.get("text", "")
            item_tokens = count_tokens(text)
            item_chars = len(text)
            
            tokens += item_tokens
            chars += item_chars
            items += 1
            max_tokens = max(max_tokens, item_tokens)
            min_tokens = min(min_tokens, item_tokens)
            
            if limit is None or items <= limit:
                limited_tokens += item_tokens
                limited_chars += item_chars
    
    average = tokens / items if items else 0.0
    actual_items = min(items, limit) if limit else items
    
    return {
        "total_items": items,
        "total_tokens": tokens,
        "total_chars": chars,
        "average_tokens": average,
        "max_tokens": max_tokens if items > 0 else 0,
        "min_tokens": int(min_tokens) if items > 0 else 0,
        "translation_limit": limit,
        "actual_items": actual_items,
        "actual_tokens": limited_tokens,
        "actual_chars": limited_chars,
    }


def main() -> None:
    """ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""

    args = parse_args()
    input_path = Path(args.input)
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    summary = summarize_tokens(input_path, args.limit)
    output_path.write_text(
        json.dumps(summary, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    print(json.dumps(summary, ensure_ascii=False))
    print("=" * 44)
    print("ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚µãƒãƒª")
    print("=" * 44)
    if args.limit:
        print(f"æŠ½å‡ºä»¶æ•°: {summary['actual_items']:,}ä»¶ (åˆ¶é™: {args.limit:,}ä»¶)")
    else:
        print(f"æŠ½å‡ºä»¶æ•°: {summary['total_items']:,}ä»¶")
    print(f"ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {summary['actual_tokens']:,}")
    print(f"å¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {summary['average_tokens']:.2f}")
    print(f"æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {summary['max_tokens']:,}")
    print(f"æœ€å°ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {summary['min_tokens']:,}")
    print("=" * 44)


if __name__ == "__main__":
    main()
